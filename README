### Proceedings (Procedimiento a seguir)

## Despliegue de contenedores por medio de Docker
En un inicio, se deslegarán los servicios necesarios para la práctica por medio de un docker compose, que obtiene diferentes imagenes de los siguientes servicios: Hive, Hadoop, MySQL y Grafana. 

## Procedimiento para cargar los ficheros AVRO en Apache Hive
Tras el despliegue, se habrá de abrir un bash en el contenedor de Hive usando Beeline, de la siguiente manera: 
```
>>>docker exec -it namenode /scripts/init-hdfs.sh
##sed -i 's/\r$//' init-hdfs.sh  if neccesary
docker cp ./config/hive-site.xml hive:/opt/hive/conf/hive-site.xml

>>>docker exec -it hive beeline -u jdbc:hive2://localhost:10000/


>>>CREATE EXTERNAL TABLE IF NOT EXISTS usuarios (
    id BIGINT,
    first_name STRING,
    last_name STRING,
    email STRING,
    gender STRING,
    ip_address STRING,
    cc BIGINT,
    country STRING,
    birthdate STRING,
    salary DOUBLE,
    title STRING,
    comments STRING
)
STORED AS AVRO
LOCATION 'hdfs:///user/hive/warehouse/usuarios'
TBLPROPERTIES ('avro.schema.url'='hdfs:///user/hive/schemas/userdata.avsc');

#Comprobar que se hayan creado los datos
>>>SELECT * FROM usuarios LIMIT 10;

docker exec -it mysql mysql -u root -p

CREATE DATABASE hive_summary;

>>>cd mysql_connector
>>>docker build -t mysql_connector .
>>>docker run --name=ejecutor --network=project2ipmd_hadoop -e MYSQL_HOST=mysql mysql_connector