### Proceedings (Procedimiento a seguir)

## Despliegue de contenedores por medio de Docker
En un inicio, se deslegarán los servicios necesarios para la práctica por medio de un docker compose, que obtiene diferentes imagenes de los siguientes servicios: Hive, Hadoop, MySQL y Grafana. 

## Procedimiento para cargar los ficheros AVRO en Apache Hive
Tras el despliegue, se habrá de abrir un bash en el contenedor de Hive usando Beeline, de la siguiente manera: 
```
>>>docker exec -it hive bash


>>>hadoop fs -mkdir -p /user/hive/warehouse/usuarios


>>>hadoop fs -put /data/userdata/*.avro /user/hive/warehouse/usuarios/

>>>hadoop fs -chmod -R 777 /user/hive/warehouse/usuarios

>>>beeline

>>>!connect jdbc:hive2://localhost:10000


>>>CREATE EXTERNAL TABLE datos (
    registration_dttm STRING,
    id BIGINT,
    first_name STRING,
    last_name STRING,
    email STRING,
    gender STRING,
    ip_address STRING,
    cc BIGINT,
    country STRING,
    birthdate STRING,
    salary DOUBLE,
    title STRING,
    comments STRING
)
STORED AS AVRO
LOCATION 'hdfs:///user/hive/warehouse/usuarios';

```